{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed166558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with Synthetic Dataset (5000+ records, three-way split)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Generate dataset (5000+ records, 2 features, binary label)\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "\n",
    "X1 = np.random.normal(0, 1, n)\n",
    "X2 = np.random.normal(0, 1, n)\n",
    "\n",
    "# logistic relationship\n",
    "w1, w2, bias = 2.0, -1.5, 0.5\n",
    "logits = w1*X1 + w2*X2 + bias\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "Y = np.random.binomial(1, probs)\n",
    "\n",
    "df = pd.DataFrame({\"X1\": X1, \"X2\": X2, \"Y\": Y})\n",
    "df.to_csv(\"logistic_dataset.csv\", index=False)\n",
    "print(\"✅ Dataset saved as logistic_dataset.csv with\", len(df), \"rows\")\n",
    "\n",
    "# 2. Split dataset (train, validation, test)\n",
    "X = df[[\"X1\",\"X2\"]]\n",
    "y = df[\"Y\"]\n",
    "\n",
    "# first split into train+val and test (80/20)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# then split train and validation (75/25 of 80 → 60% train, 20% val, 20% test)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# 3. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Evaluate on validation set (to simulate hyperparameter tuning)\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# 6. Final evaluation on test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# 7. Visualization of test predictions\n",
    "plt.scatter(X_test[\"X1\"], X_test[\"X2\"], c=y_test_pred, cmap=\"coolwarm\", alpha=0.6)\n",
    "plt.title(\"Prediction results (Test set)\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()\n",
    "\n",
    "# 8. Predict on new data\n",
    "new_data = np.array([[0.5, -1.2], [2.0, 1.0]])  # two new samples\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "preds = model.predict(new_data_scaled)\n",
    "probs = model.predict_proba(new_data_scaled)\n",
    "\n",
    "print(\"\\nNew Predictions:\")\n",
    "for i, (x, pred, prob) in enumerate(zip(new_data, preds, probs)):\n",
    "    print(f\"Sample {i+1} (X1={x[0]}, X2={x[1]}): Pred={pred}, Prob={prob[1]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
